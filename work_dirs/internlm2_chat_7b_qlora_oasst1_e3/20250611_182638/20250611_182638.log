2025/06/11 18:26:38 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1913384705
    GPU 0: NVIDIA GeForce RTX 4090
    CUDA_HOME: /usr
    NVCC: Cuda compilation tools, release 12.0, V12.0.140
    GCC: gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0
    PyTorch: 2.5.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.20.1
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1913384705
    deterministic: False
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/06/11 18:26:38 - mmengine - INFO - Config:
SYSTEM = ''
accumulative_counts = 16
batch_size = 1
betas = (
    0.9,
    0.999,
)
custom_hooks = [
    dict(
        tokenizer=dict(
            padding_side='right',
            pretrained_model_name_or_path='internlm/internlm2-chat-7b',
            trust_remote_code=True,
            type='transformers.AutoTokenizer.from_pretrained'),
        type='xtuner.engine.hooks.DatasetInfoHook'),
    dict(
        evaluation_inputs=[
            '请给我介绍五个上海的景点',
            'Please tell me five scenic spots in Shanghai',
        ],
        every_n_iters=500,
        prompt_template='xtuner.utils.PROMPT_TEMPLATE.internlm2_chat',
        system='',
        tokenizer=dict(
            padding_side='right',
            pretrained_model_name_or_path='internlm/internlm2-chat-7b',
            trust_remote_code=True,
            type='transformers.AutoTokenizer.from_pretrained'),
        type='xtuner.engine.hooks.EvaluateChatHook'),
]
data_path = 'timdettmers/openassistant-guanaco'
dataloader_num_workers = 0
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=500,
        max_keep_ckpts=2,
        type='mmengine.hooks.CheckpointHook'),
    logger=dict(
        interval=10,
        log_metric_by_epoch=False,
        type='mmengine.hooks.LoggerHook'),
    param_scheduler=dict(type='mmengine.hooks.ParamSchedulerHook'),
    sampler_seed=dict(type='mmengine.hooks.DistSamplerSeedHook'),
    timer=dict(type='mmengine.hooks.IterTimerHook'))
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation_freq = 500
evaluation_inputs = [
    '请给我介绍五个上海的景点',
    'Please tell me five scenic spots in Shanghai',
]
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr = 0.0002
max_epochs = 3
max_length = 2048
max_norm = 1
model = dict(
    llm=dict(
        pretrained_model_name_or_path='internlm/internlm2-chat-7b',
        quantization_config=dict(
            bnb_4bit_compute_dtype='torch.float16',
            bnb_4bit_quant_type='nf4',
            bnb_4bit_use_double_quant=True,
            llm_int8_has_fp16_weight=False,
            llm_int8_threshold=6.0,
            load_in_4bit=True,
            load_in_8bit=False,
            type='transformers.BitsAndBytesConfig'),
        torch_dtype='torch.float16',
        trust_remote_code=True,
        type='transformers.AutoModelForCausalLM.from_pretrained'),
    lora=dict(
        bias='none',
        lora_alpha=16,
        lora_dropout=0.1,
        r=64,
        task_type='CAUSAL_LM',
        type='peft.LoraConfig'),
    type='xtuner.model.SupervisedFinetune',
    use_varlen_attn=False)
optim_type = 'torch.optim.AdamW'
optim_wrapper = dict(
    accumulative_counts=16,
    clip_grad=dict(error_if_nonfinite=False, max_norm=1),
    dtype='float16',
    loss_scale='dynamic',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        lr=0.0002,
        type='torch.optim.AdamW',
        weight_decay=0),
    type='mmengine.optim.AmpOptimWrapper')
pack_to_max_length = True
param_scheduler = [
    dict(
        begin=0,
        by_epoch=True,
        convert_to_iter_based=True,
        end=0.09,
        start_factor=1e-05,
        type='mmengine.optim.LinearLR'),
    dict(
        begin=0.09,
        by_epoch=True,
        convert_to_iter_based=True,
        end=3,
        eta_min=0.0,
        type='mmengine.optim.CosineAnnealingLR'),
]
pretrained_model_name_or_path = 'internlm/internlm2-chat-7b'
prompt_template = 'xtuner.utils.PROMPT_TEMPLATE.internlm2_chat'
randomness = dict(deterministic=False, seed=None)
resume = False
sampler = 'mmengine.dataset.DefaultSampler'
save_steps = 500
save_total_limit = 2
sequence_parallel_size = 1
tokenizer = dict(
    padding_side='right',
    pretrained_model_name_or_path='internlm/internlm2-chat-7b',
    trust_remote_code=True,
    type='transformers.AutoTokenizer.from_pretrained')
train_cfg = dict(max_epochs=3, type='xtuner.engine.runner.TrainLoop')
train_dataloader = dict(
    batch_size=1,
    collate_fn=dict(
        type='xtuner.dataset.collate_fns.default_collate_fn',
        use_varlen_attn=False),
    dataset=dict(
        dataset=dict(
            path='timdettmers/openassistant-guanaco',
            type='datasets.load_dataset'),
        dataset_map_fn='xtuner.dataset.map_fns.oasst1_map_fn',
        max_length=2048,
        pack_to_max_length=True,
        remove_unused_columns=True,
        shuffle_before_pack=True,
        template_map_fn=dict(
            template='xtuner.utils.PROMPT_TEMPLATE.internlm2_chat',
            type='xtuner.dataset.map_fns.template_map_fn_factory'),
        tokenizer=dict(
            padding_side='right',
            pretrained_model_name_or_path='internlm/internlm2-chat-7b',
            trust_remote_code=True,
            type='transformers.AutoTokenizer.from_pretrained'),
        type='xtuner.dataset.process_hf_dataset',
        use_varlen_attn=False),
    num_workers=0,
    sampler=dict(shuffle=True, type='mmengine.dataset.DefaultSampler'))
train_dataset = dict(
    dataset=dict(
        path='timdettmers/openassistant-guanaco',
        type='datasets.load_dataset'),
    dataset_map_fn='xtuner.dataset.map_fns.oasst1_map_fn',
    max_length=2048,
    pack_to_max_length=True,
    remove_unused_columns=True,
    shuffle_before_pack=True,
    template_map_fn=dict(
        template='xtuner.utils.PROMPT_TEMPLATE.internlm2_chat',
        type='xtuner.dataset.map_fns.template_map_fn_factory'),
    tokenizer=dict(
        padding_side='right',
        pretrained_model_name_or_path='internlm/internlm2-chat-7b',
        trust_remote_code=True,
        type='transformers.AutoTokenizer.from_pretrained'),
    type='xtuner.dataset.process_hf_dataset',
    use_varlen_attn=False)
use_varlen_attn = False
visualizer = None
warmup_ratio = 0.03
weight_decay = 0
work_dir = './work_dirs/internlm2_chat_7b_qlora_oasst1_e3'

2025/06/11 18:26:45 - mmengine - WARNING - Failed to search registry with scope "mmengine" in the "builder" registry tree. As a workaround, the current "builder" registry in "xtuner" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether "mmengine" is a correct scope, or whether the registry is initialized.
2025/06/11 18:26:56 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/06/11 18:27:00 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DatasetInfoHook                    
(LOW         ) EvaluateChatHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(LOW         ) EvaluateChatHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) DatasetInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
(LOW         ) EvaluateChatHook                   
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(LOW         ) EvaluateChatHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) DatasetInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/06/11 18:27:19 - mmengine - WARNING - Dataset Dataset has no metainfo. ``dataset_meta`` in visualizer will be None.
2025/06/11 18:27:20 - mmengine - INFO - Num train samples 2164
2025/06/11 18:27:20 - mmengine - INFO - train example:
2025/06/11 18:27:20 - mmengine - INFO - <s><|im_start|>user
Que clase de atún es bueno para salud de los gatos?<|im_end|>
<|im_start|>assistant
El atún es un alimento que a muchos gatos les gusta mucho debido a su sabor y textura, pero debe ser ofrecido con moderación y con precaución ya que su consumo excesivo puede tener efectos negativos en la salud de los gatos.

En primer lugar, es importante tener en cuenta que el atún enlatado para consumo humano no está diseñado para ser la dieta principal de un gato y puede carecer de algunos nutrientes esenciales que los gatos necesitan. El atún enlatado también suele ser alto en sodio, lo que puede ser perjudicial para la salud de los gatos si se consume en grandes cantidades.

En segundo lugar, algunos tipos de atún pueden contener altos niveles de mercurio, que es tóxico para los gatos y puede causar problemas de salud graves a largo plazo. Es importante evitar dar atún fresco o enlatado diseñado para consumo humano a los gatos con regularidad y en grandes cantidades.

Si deseas darle atún a tu gato, es recomendable buscar opciones de atún especialmente diseñadas para gatos que estén etiquetadas como alimento para gatos. Estas opciones suelen tener un equilibrio nutricional adecuado para los gatos y pueden ser más seguras para su consumo. 

En general, es importante ofrecer una dieta equilibrada y adecuada para la edad y el estado de salud del gato, y hablar con un veterinario para obtener recomendaciones específicas sobre la alimentación de tu mascota.<|im_end|>
<s><|im_start|>user
If you were to image the experience of eating from only others descriptions and never having done it yourself, how would you describe it.<|im_end|>
<|im_start|>assistant
Eating is a sensory experience that involves the sense of taste, smell, and touch. Based on descriptions from others, it seems that food is a crucial aspect of human life and nourishment. People describe the act of eating as a pleasurable and satisfying activity that brings joy and comfort. The flavors, textures, and aromas of food are said to evoke various emotions and memories.

People describe different foods as sweet, sour, salty, bitter, or umami, and relate the taste to different ingredients and spices. Some describe the experience of eating as a combination of textures and flavors, such as crunchy and sweet, or creamy and savory.

The act of eating can also be a social experience, as people often gather around a table to share a meal and conversation. People describe the atmosphere of a meal as being relaxed, formal, or festive, depending on the occasion.

In conclusion, eating is a complex experience that involves multiple senses and emotions. Based on descriptions from others, it seems that eating can be a source of pleasure, comfort, and social connection.<|im_end|>
<s><|im_start|>user
Haz una redaccion sobre la historia de España<|im_end|>
<|im_start|>assistant
España es un país rico en historia, con una mezcla de culturas que se han entrelazado y han dejado su huella en la sociedad española a lo largo de los siglos. La historia de España es una historia larga y compleja que abarca desde la prehistoria hasta la actualidad.

Los primeros habitantes de España fueron los iberos, un pueblo de origen incierto que se asentó en la península ibérica hacia el 5000 a.C. Más tarde, en el siglo VIII a.C., los celtas se asentaron en la región norte de España, seguidos por los cartagineses, que se establecieron en la costa mediterránea. Los romanos conquistaron la península ibérica en el siglo III a.C., y la región se convirtió en una importante provincia del Imperio Romano.

En el siglo V d.C., los visigodos invadieron España y establecieron un reino que duró hasta el siglo VIII. Durante este tiempo, el reino visigodo se convirtió al cristianismo, lo que sentó las bases para la futura religión dominante en España.

En el siglo VIII, los musulmanes invadieron España y establecieron el Califato de Córdoba, que se convirtió en una importante potencia en Europa y el mundo árabe. Durante los siguientes siglos, la presencia musulmana en España fue significativa, y la influencia musulmana se puede ver en muchos aspectos de la cultura española, como la arquitectura, la literatura y la gastronomía.

En el siglo XI, los reinos cristianos del norte de España comenzaron a reconquistar las tierras que habían sido conquistadas por los musulmanes. Este proceso de reconquista duró varios siglos, y finalmente culminó en 1492 con la conquista de Granada por los Reyes Católicos, Isabel y Fernando.

Durante este período, España también comenzó a explorar y conquistar nuevas tierras en América y otras partes del mundo. Este período de la historia española se conoce como la Edad de Oro de España, y fue un tiempo de gran riqueza y poder para el país.

Sin embargo, en el siglo XVII, España comenzó a declinar, y perdió gran parte de su poder e influencia en el mundo. Durante los siglos XVIII y XIX, España se vio envuelta en conflictos internos y guerras con otros países europeos, y su economía sufrió un declive significativo.

En el siglo XX, España sufrió una guerra civil devastadora entre 1936 y 1939, que terminó con la victoria de los nacionalistas liderados por el General Francisco Franco. Durante los siguientes cuarenta años, España fue gobernada por un régimen autoritario y conservador bajo el mandato de Franco, que terminó con su muerte en 1975.

Desde entonces, España ha sido una democracia parlamentaria, y ha experimentado un renacimiento cultural y económico. España es conocida por su rica cultura y patrimonio, su deliciosa gastronomía y sus impresionantes paisajes naturales. También es un destino popular para los turistas, que visitan España para disfrutar de sus playas, ciudades históricas y vibrante vida nocturna.<|im_end|>
<s><|im_start|>user
Convert to Moscow time zone: 
February 07, 2023 20:00 UTC<|im_end|>
<|im_start|>assistant
February 07, 2023 22:00 in Moscow Time.<|im_end|>
<|im_start|>user
Convert the above time to Pacific Standard Time.<|im_end|>
<|im_start|>assistant
February 07, 2023 12:00 PST<|im_end|>
<s><|im_start|>user
Reformula esta frase con otras palabras: "Tras la derrota de las tropas napoleónicas, las Cortes de Cádiz regulan la vuelta de Fernando VII (el deseado) al trono de España y su acatamiento de la Constitución de 1812"<|im_end|>
<|im_start|>assistant
Después de la victoria sobre las fuerzas de Napoleón, las Cortes de Cádiz establecieron el regreso del popular rey Fernando VII al trono de España y su obediencia a la Constitución de 1812.<|im_end|>
<s><|im_start|>user
quienes toman las decisiones en la universidad nacional mayor de san marcos? tiene los alumnos alguna manera de influir en estas decisiones?<|im_end|>
<|im_start|>assistant
Las decisiones en la Universidad Nacional Mayor de San Marcos son tomadas por el Consejo Universitario, el cual está compuesto por el Rector, el Vicerrector, los Decanos de las Facultades y el Representante Estudiantil. Los alumnos tienen la oportunidad de influir en las decisiones tomada por el Consejo Universitario a través del Representante Estudiantil, quien es elegido anualmente por los estudiantes. El Representante Estudiantil es la voz de los alumnos en el Consejo Universitario, y puede presentar propuestas y discutir temas que afectan a la comunidad universitaria.<|im_end|>
<|im_start|>user
¿Cuál es el nombre del Rector?<|im_end|>
<|im_start|>assistant
El
2025/06/11 18:27:20 - mmengine - INFO - before_train in EvaluateChatHook.
2025/06/11 18:27:21 - mmengine - INFO - Sample output:
<s><|im_start|>user
请给我介绍五个上海的景点<|im_end|>
<|im_start|>assistant
上海是中国最繁华的城市之一，拥有丰富的历史、文化和现代元素。以下是五个值得一游的上海景点：

1. **外滩（The Bund）**：
   - 位于黄浦江畔，是上海最著名的地

2025/06/11 18:27:23 - mmengine - INFO - Sample output:
<s><|im_start|>user
Please tell me five scenic spots in Shanghai<|im_end|>
<|im_start|>assistant
Shanghai, the vibrant and bustling metropolis, offers a plethora of scenic spots that showcase its unique blend of modernity and history. Here are five must-visit places that offer a glimpse into Shanghai's rich cultural heritage and breathtaking landscapes

2025/06/11 18:27:23 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/06/11 18:27:23 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/06/11 18:27:23 - mmengine - INFO - Checkpoints will be saved to /home/museum/test-exp(private_bibek)/work_dirs/internlm2_chat_7b_qlora_oasst1_e3.
2025/06/11 18:27:41 - mmengine - INFO - Iter(train) [  10/6492]  lr: 9.3283e-06  eta: 3:22:51  time: 1.8778  data_time: 0.0048  memory: 11588  loss: 1.1347
2025/06/11 18:28:00 - mmengine - INFO - Iter(train) [  20/6492]  lr: 1.9691e-05  eta: 3:22:37  time: 1.8792  data_time: 0.0039  memory: 12796  loss: 1.1831  grad_norm: 0.0857
2025/06/11 18:28:19 - mmengine - INFO - Iter(train) [  30/6492]  lr: 3.0054e-05  eta: 3:22:22  time: 1.8803  data_time: 0.0039  memory: 12796  loss: 1.2499  grad_norm: 0.0857
